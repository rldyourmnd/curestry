# Glossary

## Core Concepts

### A
- **Agent**: An autonomous component that performs specific tasks
- **Curestry**: The main framework for AI application observability

### D
- **Dashboard**: Web interface for visualizing trace data and metrics
- **Decorator**: Python syntax for adding tracing functionality

### E
- **Evaluation**: Framework for assessing agent performance
- **Event**: A tracked occurrence in the system

### L
- **LLM**: Large Language Model
- **Log**: Record of system events and traces

### M
- **Metric**: Measurement of system or agent performance
- **Monitoring**: Real-time observation of system behavior

### P
- **Project**: Logical grouping of related traces
- **Provider**: LLM service provider (e.g., OpenAI)

### S
- **Session**: Container for related traces and projects
- **Storage**: System for persisting trace data

### T
- **Trace**: Record of execution flow and performance metrics
- **Tool**: Function or service that agents can use

## Technical Terms

### Performance Metrics
- **Latency**: Time taken for operation completion
- **Throughput**: Rate of operation processing
- **Token Usage**: Number of tokens consumed in LLM calls

### System Components
- **Buffer**: Temporary storage for trace data
- **Flush**: Process of writing buffered data to storage
- **Hook**: Extension point for custom functionality