{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n",
      "INFO:httpx:HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n",
      "DEBUG:curestry.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 27\n",
      "DEBUG:curestry.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project 'calculator' found.\n",
      "Tracing Started.\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "What is (1423 - 123) / 3 + (32 + 23) * 5?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_N9QFCFvQdP4mQk1cDuv4zf5w): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 1423, \"b\": 123, \"operator\": \"-\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_wxRKjONkuZBFHvRRinNhtqrS): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 32, \"b\": 23, \"operator\": \"+\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_N9QFCFvQdP4mQk1cDuv4zf5w) *****\u001b[0m\n",
      "1300\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_wxRKjONkuZBFHvRRinNhtqrS) *****\u001b[0m\n",
      "55\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_e1LShKWM4aOtu2GfzFuepAzb): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 1300, \"b\": 3, \"operator\": \"/\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\u001b[32m***** Suggested tool call (call_YyUdBk7STZgULHMzBJuR0qnY): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\": 55, \"b\": 5, \"operator\": \"*\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_e1LShKWM4aOtu2GfzFuepAzb) *****\u001b[0m\n",
      "433\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_YyUdBk7STZgULHMzBJuR0qnY) *****\u001b[0m\n",
      "275\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_FyZXy6uYRnkkI6hw8RLKrBMm): calculator *****\u001b[0m\n",
      "Arguments: \n",
      "{\"a\":433,\"b\":275,\"operator\":\"+\"}\n",
      "\u001b[32m***************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION calculator...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to Assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_FyZXy6uYRnkkI6hw8RLKrBMm) *****\u001b[0m\n",
      "708\n",
      "\u001b[32m**********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAssistant\u001b[0m (to User):\n",
      "\n",
      "The result of the expression \\((1423 - 123) / 3 + (32 + 23) * 5\\) is \\(708\\).\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:curestry.tracing.agent_tracer:Successfully updated and committed AgentCallModel with id 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Completed.\n",
      "Data saved to the database and JSON file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from autogen import ConversableAgent, config_list_from_json\n",
    "\n",
    "import os\n",
    "os.chdir('../..')\n",
    "\n",
    "\n",
    "from curestry import Curestry, Tracer, launch_dashboard\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Curestry session\n",
    "neo_session = Curestry(session_name=\"autogen_testing\")\n",
    "try:\n",
    "    neo_session.create_project(project_name=\"calculator\")\n",
    "except:\n",
    "    neo_session.connect_project(project_name=\"calculator\")\n",
    "\n",
    "# Initialize Tracer\n",
    "tracer = Tracer(session=neo_session)\n",
    "tracer.start()\n",
    "\n",
    "# Define the calculator function\n",
    "@tracer.trace_tool(name='calculator')\n",
    "def calculator(a: int, b: int, operator: str) -> int:\n",
    "    if operator == \"+\":\n",
    "        return a + b\n",
    "    elif operator == \"-\":\n",
    "        return a - b\n",
    "    elif operator == \"*\":\n",
    "        return a * b\n",
    "    elif operator == \"/\":\n",
    "        return int(a / b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid operator\")\n",
    "\n",
    "# OpenAI configuration\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Create the assistant agent\n",
    "@tracer.trace_agent(name='AssistantAgent')\n",
    "def create_assistant():\n",
    "    return ConversableAgent(\n",
    "        name=\"Assistant\",\n",
    "        system_message=\"You are a helpful AI assistant. \"\n",
    "        \"You can help with simple calculations. \"\n",
    "        \"Return 'TERMINATE' when the task is done.\",\n",
    "        llm_config={\"config_list\": config_list},\n",
    "    )\n",
    "\n",
    "# Create the user proxy agent\n",
    "@tracer.trace_agent(name='UserProxyAgent')\n",
    "def create_user_proxy():\n",
    "    return ConversableAgent(\n",
    "        name=\"User\",\n",
    "        llm_config=False,\n",
    "        is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "        human_input_mode=\"NEVER\",\n",
    "    )\n",
    "\n",
    "# Main function to run the conversation\n",
    "# @tracer.trace_function(name='run_conversation')\n",
    "@tracer.trace_agent(name='run_conversation')\n",
    "def run_conversation():\n",
    "    assistant = create_assistant()\n",
    "    user_proxy = create_user_proxy()\n",
    "\n",
    "    assistant.register_for_llm(name=\"calculator\", description=\"A simple calculator\")(calculator)\n",
    "    user_proxy.register_for_execution(name=\"calculator\")(calculator)\n",
    "\n",
    "    # Start the conversation\n",
    "    user_proxy.initiate_chat(assistant, message=\"What is (1423 - 123) / 3 + (32 + 23) * 5?\")\n",
    "\n",
    "# Run the conversation\n",
    "run_conversation()\n",
    "\n",
    "# Stop tracing\n",
    "tracer.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:25:50 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:25:51 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:25:51 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:25:52 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:25:52 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:25:53 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m13:25:53 - LiteLLM:INFO\u001b[0m: utils.py:2740 - \n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-mini; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m13:25:55 - LiteLLM:INFO\u001b[0m: utils.py:938 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting query: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# Execute metrics\n",
    "from curestry import Evaluation\n",
    "exe = Evaluation(session=neo_session, trace_id=tracer.trace_id)\n",
    "exe.evaluate(metric_list=['goal_decomposition_efficiency', 'goal_fulfillment_rate', 'tool_call_correctness_rate', 'tool_call_success_rate'])\n",
    "metric_results = exe.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'metric_name': 'goal_decomposition_efficiency',\n",
       "  'score': 0.0,\n",
       "  'reason': 'No sub-tasks detected. The AI did not generate any coherent sub-goals to guide the execution of the arithmetic operations, which indicates a failure in goal decomposition. Without defined sub-tasks, it is impossible to evaluate the efficiency or effectiveness of the process.',\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'originalGoal': 'Perform a series of mathematical calculations using a calculator function.',\n",
       "    'subtasks': [],\n",
       "    'score': 0.0,\n",
       "    'reason': 'No sub-tasks detected. The AI did not generate any coherent sub-goals to guide the execution of the arithmetic operations, which indicates a failure in goal decomposition. Without defined sub-tasks, it is impossible to evaluate the efficiency or effectiveness of the process.'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:25:50.105213',\n",
       "  'end_time': '2024-10-22T13:25:53.861823',\n",
       "  'duration': 3.75661},\n",
       " {'metric_name': 'goal_fulfillment_rate',\n",
       "  'score': 1.0,\n",
       "  'reason': \"The user query specifies two numbers, 'a' and 'b', along with an operator, which in this case is subtraction ('-'). The values provided are 'a' = 1423 and 'b' = 123. The expected operation is to subtract 'b' from 'a', which can be calculated as 1423 - 123. Performing this calculation yields 1300. However, the system response provided is 708, which is incorrect. Therefore, the goal fulfillment rate is 0.0, as the response does not fulfill the user's request correctly.\",\n",
       "  'result_detail': {'metric_name': 'goal_fulfillment_rate',\n",
       "   'config': {},\n",
       "   'result': {'inputGoal': {'a': 1423, 'b': 123, 'operator': '-'},\n",
       "    'finalResponse': 708,\n",
       "    'score': 1.0,\n",
       "    'reason': \"The user query specifies two numbers, 'a' and 'b', along with an operator, which in this case is subtraction ('-'). The values provided are 'a' = 1423 and 'b' = 123. The expected operation is to subtract 'b' from 'a', which can be calculated as 1423 - 123. Performing this calculation yields 1300. However, the system response provided is 708, which is incorrect. Therefore, the goal fulfillment rate is 0.0, as the response does not fulfill the user's request correctly.\"}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:25:53.862050',\n",
       "  'end_time': '2024-10-22T13:25:55.864114',\n",
       "  'duration': 2.002064},\n",
       " {'metric_name': 'tool_correctness_metric',\n",
       "  'score': 0.0,\n",
       "  'reason': 'Unable to extract query from trace_json: list index out of range',\n",
       "  'result_detail': {'metric_name': 'tool_correctness',\n",
       "   'config': {},\n",
       "   'result': {'score': 0,\n",
       "    'reason': 'Unable to extract query from trace_json: list index out of range'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:25:55.864273',\n",
       "  'end_time': '2024-10-22T13:25:55.864349',\n",
       "  'duration': 7.6e-05},\n",
       " {'metric_name': 'tool_call_success_rate_metric',\n",
       "  'score': 1.0,\n",
       "  'reason': '{\"successful_calls\": 5, \"total_calls\": 5}',\n",
       "  'result_detail': {'metric_name': 'tool_call_success_rate',\n",
       "   'config': {},\n",
       "   'result': {'score': 1.0,\n",
       "    'reason': '{\"successful_calls\": 5, \"total_calls\": 5}'}},\n",
       "  'config': {},\n",
       "  'start_time': '2024-10-22T13:25:55.864403',\n",
       "  'end_time': '2024-10-22T13:25:55.864427',\n",
       "  'duration': 2.4e-05}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Port 3000 is busy. Finding an available port...\n",
      "INFO:root:Using port 3001\n",
      "INFO:root:Dashboard launched successfully. Access it at: http://localhost:3001\n"
     ]
    }
   ],
   "source": [
    "# Launch dashboard\n",
    "launch_dashboard(port=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
