{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph with Curestry Integration\n",
    " This Jupyter notebook demonstrates the integration of Curestry, a powerful tracing and monitoring tool, with Langgraph, a graph-based approach to managing language models with an agent-based system to enhance the automation and decision-making capabilities of your application. This integration allows for comprehensive analysis and debugging of AI-powered systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Setup and Imports\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain langchain_openai langsmith pandas langchain_experimental matplotlib langgraph langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Literal, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "import openai\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage, \n",
    "    HumanMessage, \n",
    "    AIMessage, \n",
    "    ToolMessage\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI API using environment variables\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Initialize Curestry Session and Tracer\n",
    " Now, let's set up our Curestry session and tracer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curestry import Curestry, Tracer, Execution\n",
    "\n",
    "\n",
    "# Initialize Curestry session\n",
    "neo_session = Curestry(session_name=\"recipe_builder_assistant\")\n",
    "try:\n",
    "    neo_session.create_project(project_name=\"Recipe_Builder\")\n",
    "except:\n",
    "    neo_session.connect_project(project_name=\"Recipe_Builder\")\n",
    "\n",
    "# Create tracer\n",
    "tracer = Tracer(session=neo_session)\n",
    "tracer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " # Define Agents and Tools\n",
    "Now, let's create our AI tools using langgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.trace_agent(name=\"RecipeInstructions\")\n",
    "class RecipeInstructions(BaseModel):\n",
    "    \"\"\"Instructions for creating a recipe.\"\"\"\n",
    "    dish_name: str\n",
    "    servings: int\n",
    "    dietary_restrictions: List[str]\n",
    "    cooking_time: str\n",
    "    difficulty_level: str\n",
    "    ingredients: List[str]\n",
    "    special_equipment: List[str]\n",
    "\n",
    "@tracer.trace_agent(name=\"RecipeBuilder\")\n",
    "class RecipeBuilder:\n",
    "    def __init__(self):\n",
    "        self.template = \"\"\"You are a helpful recipe building assistant. Your job is to help users create and customize recipes.\n",
    "\n",
    "You should gather the following information:\n",
    "- Name of the dish they want to make\n",
    "- Number of servings needed\n",
    "- Any dietary restrictions or preferences\n",
    "- Desired cooking time\n",
    "- Cooking skill level\n",
    "- Available ingredients or preferred ingredients\n",
    "- Available cooking equipment\n",
    "\n",
    "If any information is missing or unclear, ask for clarification. Once you have all the necessary information, call the relevant tool to generate the recipe.\n",
    "\n",
    "Remember to:\n",
    "- Be specific about ingredient quantities\n",
    "- Consider dietary restrictions carefully\n",
    "- Suggest alternatives for uncommon ingredients\n",
    "- Provide clear, step-by-step instructions\"\"\"\n",
    "\n",
    "        self.llm = ChatOpenAI(temperature=0.7)\n",
    "        self.llm_with_tool = self.llm.bind_tools([RecipeInstructions])\n",
    "\n",
    "    @tracer.trace_tool(name=\"get_messages_info\")\n",
    "    def get_messages_info(self, messages):\n",
    "        return [SystemMessage(content=self.template)] + messages\n",
    "\n",
    "    @tracer.trace_tool(name=\"info_chain\")\n",
    "    def info_chain(self, state):\n",
    "        messages = self.get_messages_info(state[\"messages\"])\n",
    "        response = self.llm_with_tool.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    @tracer.trace_tool(name=\"get_recipe_messages\")\n",
    "    def get_recipe_messages(self, messages: list):\n",
    "        tool_call = None\n",
    "        other_msgs = []\n",
    "        for m in messages:\n",
    "            if isinstance(m, AIMessage) and m.tool_calls:\n",
    "                tool_call = m.tool_calls[0][\"args\"]\n",
    "            elif isinstance(m, ToolMessage):\n",
    "                continue\n",
    "            elif tool_call is not None:\n",
    "                other_msgs.append(m)\n",
    "        \n",
    "        recipe_system = \"\"\"Based on the following requirements, create a detailed recipe with:\n",
    "1. List of ingredients with quantities\n",
    "2. Required equipment\n",
    "3. Step-by-step preparation instructions\n",
    "4. Cooking tips and timing\n",
    "5. Serving suggestions\n",
    "6. Storage instructions if applicable\n",
    "\n",
    "Recipe Requirements:\n",
    "{reqs}\"\"\"\n",
    "        return [SystemMessage(content=recipe_system.format(reqs=tool_call))] + other_msgs\n",
    "\n",
    "    @tracer.trace_tool(name=\"recipe_gen_chain\")\n",
    "    def recipe_gen_chain(self, state):\n",
    "        messages = self.get_recipe_messages(state[\"messages\"])\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.trace_agent(name=\"NutritionAnalyzer\")\n",
    "class NutritionAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.template = \"\"\"You are a nutrition analysis assistant. Your job is to analyze the nutritional content of recipes.\n",
    "\n",
    "Given a recipe, you should provide:\n",
    "1. Total calories per serving\n",
    "2. Macronutrient breakdown (protein, carbs, fats)\n",
    "3. Key vitamins and minerals\n",
    "4. Potential allergens\n",
    "5. Suggestions for making the recipe healthier (if applicable)\n",
    "\n",
    "Be as accurate as possible with your estimations. If you're unsure about any information, state that it's an approximation.\"\"\"\n",
    "\n",
    "        self.llm = ChatOpenAI(temperature=0.3)\n",
    "\n",
    "    @tracer.trace_tool(name=\"get_nutrition_messages\")\n",
    "    def get_nutrition_messages(self, messages):\n",
    "        recipe = None\n",
    "        for m in messages:\n",
    "            if isinstance(m, AIMessage) and not m.tool_calls:\n",
    "                recipe = m.content\n",
    "                break\n",
    "        \n",
    "        if recipe is None:\n",
    "            return [SystemMessage(content=\"No recipe found to analyze.\")]\n",
    "        \n",
    "        return [\n",
    "            SystemMessage(content=self.template),\n",
    "            HumanMessage(content=f\"Please analyze the nutritional content of this recipe:\\n\\n{recipe}\")\n",
    "        ]\n",
    "\n",
    "    @tracer.trace_tool(name=\"nutrition_analysis_chain\")\n",
    "    def nutrition_analysis_chain(self, state):\n",
    "        messages = self.get_nutrition_messages(state[\"messages\"])\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tracer.trace_agent(name=\"CookingTipsAgent\")\n",
    "class CookingTipsAgent:\n",
    "    def __init__(self):\n",
    "        self.template = \"\"\"You are a cooking tips and techniques expert. Your job is to provide helpful advice and tips for the given recipe.\n",
    "\n",
    "Given a recipe, you should provide:\n",
    "1. General cooking techniques relevant to the recipe\n",
    "2. Tips for ingredient preparation\n",
    "3. Suggestions for enhancing flavors\n",
    "4. Common mistakes to avoid\n",
    "5. Time-saving tricks (if applicable)\n",
    "6. Plating and presentation ideas\n",
    "\n",
    "Ensure your tips are specific to the recipe and helpful for cooks of all skill levels.\"\"\"\n",
    "\n",
    "        self.llm = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "    @tracer.trace_tool(name=\"get_cooking_tips_messages\")\n",
    "    def get_cooking_tips_messages(self, messages):\n",
    "        recipe = None\n",
    "        for m in messages:\n",
    "            if isinstance(m, AIMessage) and not m.tool_calls:\n",
    "                recipe = m.content\n",
    "                break\n",
    "        \n",
    "        if recipe is None:\n",
    "            return [SystemMessage(content=\"No recipe found to provide tips for.\")]\n",
    "        \n",
    "        return [\n",
    "            SystemMessage(content=self.template),\n",
    "            HumanMessage(content=f\"Please provide cooking tips and techniques for this recipe:\\n\\n{recipe}\")\n",
    "        ]\n",
    "\n",
    "    @tracer.trace_tool(name=\"cooking_tips_chain\")\n",
    "    def cooking_tips_chain(self, state):\n",
    "        messages = self.get_cooking_tips_messages(state[\"messages\"])\n",
    "        response = self.llm.invoke(messages)\n",
    "        return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing state graphs, saving memory, handling messages, and typing annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State management\n",
    "\n",
    "@tracer.trace_tool(name=\"get_state\")\n",
    "def get_state(state):\n",
    "    messages = state[\"messages\"]\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"add_tool_message\"\n",
    "    elif isinstance(messages[-1], AIMessage) and not messages[-1].tool_calls:\n",
    "        if any(\"nutrition\" in m.content.lower() for m in messages[-3:]):\n",
    "            return \"cooking_tips\"\n",
    "        return \"nutrition_analysis\"\n",
    "    elif not isinstance(messages[-1], HumanMessage):\n",
    "        return END\n",
    "    return \"info\"\n",
    "\n",
    "@tracer.trace_agent(name=\"State\")\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Initialize workflow\n",
    "memory = MemorySaver()\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Initialize agents\n",
    "recipe_builder = RecipeBuilder()\n",
    "nutrition_analyzer = NutritionAnalyzer()\n",
    "cooking_tips_agent = CookingTipsAgent()\n",
    "\n",
    "# Add nodes to workflow\n",
    "workflow.add_node(\"info\", recipe_builder.info_chain)\n",
    "workflow.add_node(\"recipe\", recipe_builder.recipe_gen_chain)\n",
    "workflow.add_node(\"nutrition_analysis\", nutrition_analyzer.nutrition_analysis_chain)\n",
    "workflow.add_node(\"cooking_tips\", cooking_tips_agent.cooking_tips_chain)\n",
    "\n",
    "@workflow.add_node\n",
    "def add_tool_message(state: State):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Recipe generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Add edges to workflow\n",
    "workflow.add_conditional_edges(\"info\", get_state, [\"add_tool_message\", \"info\", \"nutrition_analysis\", \"cooking_tips\", END])\n",
    "workflow.add_edge(\"add_tool_message\", \"recipe\")\n",
    "workflow.add_edge(\"recipe\", \"nutrition_analysis\")\n",
    "workflow.add_edge(\"nutrition_analysis\", \"cooking_tips\")\n",
    "workflow.add_edge(\"cooking_tips\", END)\n",
    "workflow.add_edge(START, \"info\")\n",
    "\n",
    "# Compile graph\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying a PNG image of a graph generated from a LangGraph instance using Mermaid visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% \n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main interaction loop\n",
    "def run_interaction():\n",
    "    cached_human_responses = [\n",
    "        \"I want to make chocolate chip cookies\",\n",
    "        \"6 servings, no nuts, beginner friendly, 30 minutes cooking time\",\n",
    "        \"I have basic baking equipment and ingredients\",\n",
    "        \"Can you analyze the nutritional content of this recipe?\",\n",
    "        \"Any cooking tips for making these cookies?\",\n",
    "        \"q\"\n",
    "    ]\n",
    "    cached_response_index = 0\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user = input(\"User (q/Q to quit): \")\n",
    "        except:\n",
    "            user = cached_human_responses[cached_response_index]\n",
    "            cached_response_index += 1\n",
    "            \n",
    "        print(f\"User (q/Q to quit): {user}\")\n",
    "        \n",
    "        if user in {\"q\", \"Q\"}:\n",
    "            print(\"AI: Thank you for using the Recipe Builder, Nutrition Analyzer, and Cooking Tips Assistant! Happy cooking!\")\n",
    "            break\n",
    "            \n",
    "        output = None\n",
    "        for output in graph.stream(\n",
    "            {\"messages\": [HumanMessage(content=user)]}, \n",
    "            config=config, \n",
    "            stream_mode=\"updates\"\n",
    "        ):\n",
    "            last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "            last_message.pretty_print()\n",
    "\n",
    "        if output and \"cooking_tips\" in output:\n",
    "            print(\"Recipe, nutrition analysis, and cooking tips completed! Let me know if you need any modifications or have questions!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Evaluation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics Evaluation System\n",
    "def execute_metrics(neo_session, trace_id):\n",
    "    \"\"\"Execute and return metrics analysis.\"\"\"\n",
    "    exe = Execution(session=neo_session, trace_id=trace_id)\n",
    "    exe.execute(metric_list=[\n",
    "        'goal_decomposition_efficiency',\n",
    "        'goal_fulfillment_rate',\n",
    "        'tool_call_success_rate_metric'\n",
    "    ])\n",
    "    return exe.get_results()\n",
    "\n",
    "def print_metrics_results(metric_results):\n",
    "    \"\"\"Print the metrics results in a formatted way.\"\"\"\n",
    "    print(\"\\nMetrics Results:\")\n",
    "    print(metric_results)\n",
    "\n",
    "def launch_metrics_dashboard(neo_session):\n",
    "    \"\"\"Launch the Curestry metrics dashboard.\"\"\"\n",
    "    neo_session.launch_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        run_interaction()\n",
    "    finally:\n",
    "        tracer.stop()\n",
    "        print(f\"Trace ID: {tracer.trace_id}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = execute_metrics(neo_session, tracer.trace_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print_metrics_results(results)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch dashboard\n",
    "launch_metrics_dashboard(neo_session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
